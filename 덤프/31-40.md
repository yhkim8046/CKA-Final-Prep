Q31 〔복원〕

문제:
Namespace debug에 라벨 app=netshoot을 가진 Pod 배포.
그 파드 안에서 nslookup kubernetes.default.svc.cluster.local을 실행하여 결과 확인.

해법:

kubectl create ns debug
kubectl run netshoot --image=nicolaka/netshoot -n debug --labels=app=netshoot -- sleep 3600
kubectl exec -n debug -it netshoot -- nslookup kubernetes.default.svc.cluster.local

Q32 〔복원〕

문제:
CoreDNS 서비스 이름과 Endpoints가 존재하지 않는 경우, DNS 확인 실패한 노드 식별.
(네트워크/서비스 디버깅 목적)

해법:

kubectl get svc -n kube-system kube-dns
kubectl get ep -n kube-system kube-dns
# 없는 경우, CoreDNS 재배포 필요
kubectl rollout restart deploy coredns -n kube-system
# 노드별 확인
kubectl debug node/worker-1 -it --image=busybox -- nslookup kubernetes.default

Q33 〔복원〕

문제:
CRD 관련 문제 — 새로운 CustomResourceDefinition(CRD) 생성 및 확인.
예: CRD 이름 crontabs.stable.example.com.

해법:

apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: crontabs.stable.example.com
spec:
  group: stable.example.com
  versions:
  - name: v1
    served: true
    storage: true
    schema:
      openAPIV3Schema:
        type: object
        properties:
          spec:
            type: object
            properties:
              cronSpec:
                type: string
              image:
                type: string
              replicas:
                type: integer
  scope: Namespaced
  names:
    plural: crontabs
    singular: crontab
    kind: CronTab
    shortNames:
    - ct

kubectl apply -f crd.yaml
kubectl get crd

Q34

문제:
etcd 스냅샷 생성

endpoint: https://127.0.0.1:2379

출력 경로: /srv/data/etcd-snapshot.db

인증서 경로:

CA: /opt/KUCM00302/ca.crt

cert: /opt/KUCM00302/etcd-client.crt

key: /opt/KUCM00302/etcd-client.key

해법:

export ETCDCTL_API=3
etcdctl --endpoints=https://127.0.0.1:2379 \
  --cacert=/opt/KUCM00302/ca.crt \
  --cert=/opt/KUCM00302/etcd-client.crt \
  --key=/opt/KUCM00302/etcd-client.key \
  snapshot save /srv/data/etcd-snapshot.db

Q35 〔복원〕

문제:
Pod foo의 로그 중 특정 키워드만 추출하여 /opt/KULM00201/foo에 저장.

해법:

kubectl logs foo | grep "KEYWORD" > /opt/KULM00201/foo

Q36 〔복원〕

문제:
Pod nginx의 레플리카 수를 5로 scale 조정.

해법:

kubectl scale deployment nginx --replicas=5
kubectl get deploy nginx

Q37

문제:
특정 Node Selector로 Pod 실행

이름: nginx-kusc00101

이미지: nginx

nodeSelector: disk=ssd

해법 (nginx-kusc00101.yaml):

apiVersion: v1
kind: Pod
metadata:
  name: nginx-kusc00101
spec:
  nodeSelector:
    disk: ssd
  containers:
  - name: nginx
    image: nginx

kubectl apply -f nginx-kusc00101.yaml

Q38 〔복원〕

문제:
컨테이너 런타임(Containerd)이 만든 가상 네트워크 인터페이스 확인.

해법:

ip link
# containerd는 보통 cni0 브리지와 veth-* 인터페이스 생성

Q39 〔복원〕

문제:
Pod foo 로그를 특정 키워드만 추출하여 /opt/KULM00201/foo 파일에 기록.

해법:

kubectl logs foo | grep "SOMETHING" > /opt/KULM00201/foo

Q40

문제:
Ready 상태의 워커 노드 개수를 확인 (단, NoSchedule taint가 있는 노드는 제외)
→ 결과를 /opt/KUCC00104/kucc00104.txt에 저장

해법 (간단):

kubectl get nodes --no-headers \
  | grep -w 'Ready' \
  | grep -v 'master' \
  | wc -l > /opt/KUCC00104/kucc00104.txt


해법 (정밀 - taint 검사까지):

kubectl get nodes -o json \
  | jq '[.items[] 
    | select(any(.status.conditions[]; .type=="Ready" and .status=="True")) 
    | select(all(.spec.taints[]?; .effect!="NoSchedule"))] 
    | length' > /opt/KUCC00104/kucc00104.txt