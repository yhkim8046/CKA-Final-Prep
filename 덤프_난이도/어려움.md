Q7

문제:
PersistentVolume 생성

이름: app-data

용량: 2Gi

AccessMode: ReadWriteMany

hostPath: /srv/app-data

답:

apiVersion: v1
kind: PersistentVolume
metadata:
  name: app-data
spec:
  capacity:
    storage: 2Gi
  accessModes:
  - ReadWriteMany
  storageClassName: shared
  hostPath:
    path: "/srv/app-data"

Q8

문제:
모든 PersistentVolume을 용량 기준 정렬해서 /opt/KUCC00102/volume_list에 저장.

답:

kubectl get pv --sort-by=.spec.capacity.storage -o wide > /opt/KUCC00102/volume_list

Q13

문제:
라벨 name=cpu-utilizer인 파드 중 CPU 사용률이 가장 높은 파드 이름을
/opt/KUTR00102/KUTR00102.txt에 기록.

답:

kubectl top pods -l name=cpu-utilizer --no-headers \
  | sort -k2 -nr | head -n1 | awk '{print $1}' > /opt/KUTR00102/KUTR00102.txt

Q15

문제:
Pod hungry-bear에 InitContainer 추가.

/workdir/calm.txt 파일 생성 → 메인 컨테이너 실행 조건.

답:

apiVersion: v1
kind: Pod
metadata:
  name: hungry-bear
spec:
  volumes:
  - name: workdir
    emptyDir: {}
  initContainers:
  - name: init-calm
    image: busybox
    command: ["sh","-c","mkdir -p /workdir && : > /workdir/calm.txt"]
    volumeMounts:
    - name: workdir
      mountPath: /workdir
  containers:
  - name: main
    image: busybox
    command: ["sh","-c","[ -f /workdir/calm.txt ] || exit 1; sleep 3600"]
    volumeMounts:
    - name: workdir
      mountPath: /workdir

Q19

문제:
Pod nginx-dev의 이미지 버전을 JsonPath로 출력.

답:

kubectl get pod nginx-dev -o jsonpath='{.spec.containers[0].image}{"\n"}'

Q24

문제:
ClusterRole pod-reader 생성 (get, list, watch 권한).
Namespace development의 ServiceAccount john에 바인딩.

답:

kubectl create clusterrole pod-reader --verb=get,list,watch --resource=pods
kubectl create rolebinding john-binding --clusterrole=pod-reader \
  --serviceaccount=development:john -n development

Q29

문제:
모든 Pod의 이름과 네임스페이스를 JsonPath로 출력.

답:

kubectl get pods -A -o=jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.metadata.namespace}{"\n"}{end}'

Q34

문제:
etcd 스냅샷 생성

endpoint: https://127.0.0.1:2379

저장 경로: /srv/data/etcd-snapshot.db

인증서: /opt/KUCM00302/ca.crt, /opt/KUCM00302/etcd-client.crt, /opt/KUCM00302/etcd-client.key

답:

export ETCDCTL_API=3
etcdctl --endpoints=https://127.0.0.1:2379 \
  --cacert=/opt/KUCM00302/ca.crt \
  --cert=/opt/KUCM00302/etcd-client.crt \
  --key=/opt/KUCM00302/etcd-client.key \
  snapshot save /srv/data/etcd-snapshot.db

Q37

문제:
특정 Node Selector로 Pod 실행

이름: nginx-kusc00101

이미지: nginx

nodeSelector: disk=ssd

답:

apiVersion: v1
kind: Pod
metadata:
  name: nginx-kusc00101
spec:
  nodeSelector:
    disk: ssd
  containers:
  - name: nginx
    image: nginx

Q40

문제:
Ready 상태의 워커 노드 개수를 확인 (NoSchedule taint 제외).
→ /opt/KUCC00104/kucc00104.txt에 저장.

답 (간단):

kubectl get nodes --no-headers \
  | grep -w 'Ready' \
  | grep -v 'master' \
  | wc -l > /opt/KUCC00104/kucc00104.txt


답 (정밀, jq 사용):

kubectl get nodes -o json \
  | jq '[.items[] 
    | select(any(.status.conditions[]; .type=="Ready" and .status=="True")) 
    | select(all(.spec.taints[]?; .effect!="NoSchedule"))] 
    | length' > /opt/KUCC00104/kucc00104.txt